{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to filter data for Dr-LLaVA Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ecg_df = pd.read_csv('../../data/mimic-acute-mi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>ecg_time</th>\n",
       "      <th>st_elevation</th>\n",
       "      <th>st_depression</th>\n",
       "      <th>t_wave</th>\n",
       "      <th>Acute_MI</th>\n",
       "      <th>study_id</th>\n",
       "      <th>text</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>comments</th>\n",
       "      <th>troponin</th>\n",
       "      <th>STEMI</th>\n",
       "      <th>NSTEMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29196424.0</td>\n",
       "      <td>2087-05-08 00:05:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44673611</td>\n",
       "      <td>Allergies: \\nlisinopril / vancomycin\\n \\nChief...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21091437.0</td>\n",
       "      <td>2087-05-08 00:05:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43819938</td>\n",
       "      <td>Allergies: \\namitriptyline / Sulfa (Sulfonamid...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>cTropnT &gt; 0.10 ng/mL suggests Acute MI.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21236438.0</td>\n",
       "      <td>2088-04-14 02:58:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47239325</td>\n",
       "      <td>Allergies: \\nMULTIPLE - SEE LIST **** / amoxic...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>cTropnT &gt; 0.10 ng/mL suggests Acute MI.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23821411.0</td>\n",
       "      <td>2089-12-11 00:06:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41010651</td>\n",
       "      <td>Allergies: \\nchlorhexidine\\n \\nChief Complaint...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>cTropnT &gt; 0.10 ng/mL suggests Acute MI.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28274927.0</td>\n",
       "      <td>2090-08-21 00:12:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49791716</td>\n",
       "      <td>Allergies: \\nNo Known Allergies / Adverse Drug...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id             ecg_time  st_elevation  st_depression  t_wave  \\\n",
       "0  29196424.0  2087-05-08 00:05:00             0              0       0   \n",
       "1  21091437.0  2087-05-08 00:05:00             0              0       0   \n",
       "3  21236438.0  2088-04-14 02:58:00             0              0       0   \n",
       "4  23821411.0  2089-12-11 00:06:00             0              0       0   \n",
       "5  28274927.0  2090-08-21 00:12:00             0              0       0   \n",
       "\n",
       "   Acute_MI  study_id                                               text  \\\n",
       "0         0  44673611  Allergies: \\nlisinopril / vancomycin\\n \\nChief...   \n",
       "1         0  43819938  Allergies: \\namitriptyline / Sulfa (Sulfonamid...   \n",
       "3         0  47239325  Allergies: \\nMULTIPLE - SEE LIST **** / amoxic...   \n",
       "4         0  41010651  Allergies: \\nchlorhexidine\\n \\nChief Complaint...   \n",
       "5         0  49791716  Allergies: \\nNo Known Allergies / Adverse Drug...   \n",
       "\n",
       "   valuenum                                 comments  troponin  STEMI  NSTEMI  \n",
       "0       NaN                                      NaN         0      0       0  \n",
       "1      0.03  cTropnT > 0.10 ng/mL suggests Acute MI.         1      0       0  \n",
       "3      0.02  cTropnT > 0.10 ng/mL suggests Acute MI.         1      0       0  \n",
       "4      0.07  cTropnT > 0.10 ng/mL suggests Acute MI.         1      0       0  \n",
       "5       NaN                                      NaN         0      0       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272109, 13)\n"
     ]
    }
   ],
   "source": [
    "all_ecg_df = all_ecg_df[~all_ecg_df['text'].isna()]\n",
    "all_ecg_df = all_ecg_df[(all_ecg_df['troponin'] & ~all_ecg_df['valuenum'].isnull() & ~all_ecg_df['comments'].isnull()) | (all_ecg_df['troponin'] == 0)]\n",
    "display(all_ecg_df.head())\n",
    "print(all_ecg_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8482\n",
      "30144\n",
      "\n",
      "31925\n",
      "1572\n",
      "493\n"
     ]
    }
   ],
   "source": [
    "print(all_ecg_df.STEMI.sum())\n",
    "print(all_ecg_df.NSTEMI.sum())\n",
    "print()\n",
    "\n",
    "print(all_ecg_df.st_elevation.sum())\n",
    "print(all_ecg_df.st_depression.sum())\n",
    "print(all_ecg_df.t_wave.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled DataFrame Shape: (30000, 13)\n",
      "STEMI Count: 2421\n",
      "NSTEMI Count: 5547\n",
      "ST Elevation Count: 6969\n",
      "ST Depression Count: 707\n",
      "T-wave Inversion Count: 354\n"
     ]
    }
   ],
   "source": [
    "# Function to sample rows for a specific condition\n",
    "def sample_condition(df, condition, count, sampled_indices):\n",
    "    condition_df = df[condition & ~df.index.isin(sampled_indices)]\n",
    "    if len(condition_df) < count:\n",
    "        raise ValueError(f\"Not enough rows to sample for condition: {condition}\")\n",
    "    sampled = condition_df.sample(n=count, random_state=RANDOM_STATE)\n",
    "    sampled_dfs.append(sampled)\n",
    "    return sampled.index\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Define the minimum required counts for each ECG category\n",
    "required_counts = {\n",
    "    'STEMI': 900,\n",
    "    'NSTEMI': 3200,\n",
    "    'ST_elevation': 3500,\n",
    "    'ST_depression': 500,\n",
    "    'T_wave_inversion': 300\n",
    "}\n",
    "\n",
    "# Create a copy of the original dataframe to work with\n",
    "df = all_ecg_df.copy()\n",
    "\n",
    "# Initialize an empty list to store the sampled dataframes\n",
    "sampled_dfs = []\n",
    "\n",
    "# Initialize a set to keep track of sampled indices to avoid duplication where necessary\n",
    "sampled_indices = set()\n",
    "\n",
    "# Sample STEMI ECGs\n",
    "sampled_indices.update(sample_condition(\n",
    "    df,\n",
    "    df['STEMI'] == 1,\n",
    "    required_counts['STEMI'],\n",
    "    sampled_indices\n",
    "))\n",
    "\n",
    "# Sample NSTEMI ECGs\n",
    "sampled_indices.update(sample_condition(\n",
    "    df,\n",
    "    df['NSTEMI'] == 1,\n",
    "    required_counts['NSTEMI'],\n",
    "    sampled_indices\n",
    "))\n",
    "\n",
    "# Sample ST-elevation ECGs\n",
    "sampled_indices.update(sample_condition(\n",
    "    df,\n",
    "    df['st_elevation'] == 1,\n",
    "    required_counts['ST_elevation'],\n",
    "    sampled_indices\n",
    "))\n",
    "\n",
    "# Sample ST-depression ECGs\n",
    "sampled_indices.update(sample_condition(\n",
    "    df,\n",
    "    df['st_depression'] == 1,\n",
    "    required_counts['ST_depression'],\n",
    "    sampled_indices\n",
    "))\n",
    "\n",
    "# Sample T-wave inversion ECGs\n",
    "sampled_indices.update(sample_condition(\n",
    "    df,\n",
    "    df['t_wave'] == 1,\n",
    "    required_counts['T_wave_inversion'],\n",
    "    sampled_indices\n",
    "))\n",
    "\n",
    "# Concatenate all sampled dataframes\n",
    "downsampled_df = pd.concat(sampled_dfs)\n",
    "\n",
    "# Calculate the remaining number of rows to reach 30,000\n",
    "remaining_rows = 30000 - len(downsampled_df)\n",
    "\n",
    "# Check if there are enough remaining rows to sample\n",
    "if remaining_rows > 0:\n",
    "    # Exclude already sampled indices\n",
    "    remaining_df = df[~df.index.isin(sampled_indices)]\n",
    "    \n",
    "    if len(remaining_df) < remaining_rows:\n",
    "        raise ValueError(\"Not enough remaining rows to reach 30,000 after sampling required categories.\")\n",
    "    \n",
    "    # Sample the remaining rows\n",
    "    remaining_sampled = remaining_df.sample(n=remaining_rows, random_state=RANDOM_STATE)\n",
    "    downsampled_df = pd.concat([downsampled_df, remaining_sampled])\n",
    "\n",
    "# Shuffle the final dataframe\n",
    "downsampled_df = downsampled_df.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "# Optional: Verify the counts\n",
    "print(\"Downsampled DataFrame Shape:\", downsampled_df.shape)\n",
    "print(\"STEMI Count:\", downsampled_df['STEMI'].sum())\n",
    "print(\"NSTEMI Count:\", downsampled_df['NSTEMI'].sum())\n",
    "print(\"ST Elevation Count:\", (downsampled_df['st_elevation'] == 1).sum())\n",
    "print(\"ST Depression Count:\", (downsampled_df['st_depression'] == 1).sum())\n",
    "print(\"T-wave Inversion Count:\", (downsampled_df['t_wave'] == 1).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_df.to_csv('../../data/mimic-acute-mi_modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/conversations_new.json') as f:\n",
    "    conversations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272109/272109 [22:45<00:00, 199.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conversations after filtering: 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "study_id_list = downsampled_df['study_id'].tolist()\n",
    "filtered_conversations = [item for item in tqdm(conversations) if int(item['id']) in downsampled_df['study_id'].tolist()]\n",
    "print(f\"Number of conversations after filtering: {len(filtered_conversations)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/conversations_modelling.json', 'w') as f:\n",
    "    json.dump(filtered_conversations, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training study_ids: 24000\n",
      "Testing study_ids: 6000\n",
      "Training DataFrame shape: (24000, 13)\n",
      "Test DataFrame shape: (6000, 13)\n",
      "Training conversations count: 24000\n",
      "Test conversations count: 6000\n",
      "Training and test DataFrames saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "RANDOM_STATE = 42\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "# Paths to JSON files\n",
    "train_json_path = '../../data/train_conversations.json'\n",
    "test_json_path = '../../data/test_conversations.json'\n",
    "\n",
    "# Paths to save split DataFrames\n",
    "train_df_path = '../../data/train_downsampled_df.csv'\n",
    "test_df_path = '../../data/test_downsampled_df.csv'\n",
    "\n",
    "\n",
    "# 1. Split the study_ids\n",
    "study_ids = downsampled_df['study_id'].astype(int).unique()\n",
    "train_ids, test_ids = train_test_split(\n",
    "    study_ids,\n",
    "    test_size=1 - TRAIN_RATIO,\n",
    "    random_state=RANDOM_STATE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Training study_ids: {len(train_ids)}\")\n",
    "print(f\"Testing study_ids: {len(test_ids)}\")\n",
    "\n",
    "# 2. Create training and test DataFrames\n",
    "train_df = downsampled_df[downsampled_df['study_id'].astype(int).isin(train_ids)].reset_index(drop=True)\n",
    "test_df = downsampled_df[downsampled_df['study_id'].astype(int).isin(test_ids)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Training DataFrame shape: {train_df.shape}\")\n",
    "print(f\"Test DataFrame shape: {test_df.shape}\")\n",
    "\n",
    "# 3. Split conversations\n",
    "train_conversations = [conv for conv in filtered_conversations if int(conv['id']) in train_ids]\n",
    "test_conversations = [conv for conv in filtered_conversations if int(conv['id']) in test_ids]\n",
    "\n",
    "print(f\"Training conversations count: {len(train_conversations)}\")\n",
    "print(f\"Test conversations count: {len(test_conversations)}\")\n",
    "\n",
    "# 4. Save the split DataFrames\n",
    "train_df.to_csv(train_df_path, index=False)\n",
    "test_df.to_csv(test_df_path, index=False)\n",
    "print(\"Training and test DataFrames saved successfully!\")\n",
    "\n",
    "# 5. Save the conversations\n",
    "with open(train_json_path, 'w') as f:\n",
    "    json.dump(train_conversations, f)\n",
    "\n",
    "with open(test_json_path, 'w') as f:\n",
    "    json.dump(test_conversations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_id_set = downsampled_df['study_id'].tolist()\n",
    "with open('../../data/modelling_ids.json', 'w') as json_file:\n",
    "    json.dump(list(study_id_set), json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Represent Test conversations as single QA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing conversations:   0%|          | 0/6000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing conversations: 100%|██████████| 6000/6000 [00:00<00:00, 28678.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total QA pairs extracted: 22580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def transform_to_qa(test_conversations):\n",
    "    qa_list = []  # List to hold all QA pairs\n",
    "\n",
    "    # Iterate over each conversation item with a progress bar\n",
    "    for item in tqdm(test_conversations, desc='Processing conversations'):\n",
    "        convs = item.get('conversations', [])\n",
    "        conv_id = item.get('id')\n",
    "        image = item.get('image')\n",
    "        diagnosis = item.get('diagnosis')\n",
    "\n",
    "        # Initialize index\n",
    "        i = 0\n",
    "        while i < len(convs):\n",
    "            # Check if the current turn is from 'human'\n",
    "            if convs[i].get('from') == 'human':\n",
    "                human_msg = convs[i].get('value', '').strip()\n",
    "\n",
    "                # Check if the next turn exists and is from 'gpt'\n",
    "                if i + 1 < len(convs) and convs[i + 1].get('from') == 'gpt':\n",
    "                    gpt_msg = convs[i + 1].get('value', '').strip()\n",
    "\n",
    "                    # Append the QA pair to the list, maintaining 'from' and 'value'\n",
    "                    qa_list.append({\n",
    "                        'id': conv_id,\n",
    "                        'image': image,\n",
    "                        'conversations': [\n",
    "                            {\n",
    "                                'from': 'human',\n",
    "                                'value': human_msg\n",
    "                            },\n",
    "                            {\n",
    "                                'from': 'gpt',\n",
    "                                'value': gpt_msg\n",
    "                            }\n",
    "                        ],\n",
    "                        #'diagnosis': diagnosis\n",
    "                    })\n",
    "\n",
    "                    # Move to the next pair\n",
    "                    i += 2\n",
    "                else:\n",
    "                    # If there's no corresponding 'gpt' response, skip to next\n",
    "                    i += 1\n",
    "            else:\n",
    "                # If the current turn is not from 'human', skip to next\n",
    "                i += 1\n",
    "    return qa_list\n",
    "\n",
    "qa_list = transform_to_qa(test_conversations)\n",
    "\n",
    "print(f\"Total QA pairs extracted: {len(qa_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 47548370,\n",
       "  'image': '47548370.jpeg',\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': \"<image>\\nAllergies: \\nCodeine / Aspirin / Children's Advil Allergy Sinus / Quinine / \\nAdvil\\n \\nChief Complaint:\\nNonhealing right first toe amputation site\\n \\nMajor Surgical or Invasive Procedure:\\n___ Right lower extremity diagnostic angiogram\\n___ Right below knee amputation\\n\\n \\nHistory of Present Illness:\\n___ woman with known PAD status post right SFA stent in \\n___ secondary to right hallux gangrene. She eventually \\nunderwent right hallux amputation by Dr. ___.  She presents \\nto clinic with progressive infection in the right hallux \\namputation site and is admitted to the hospital for IV \\nantibiotics and to reassess perfusion.\\n\\n \\nPast Medical History:\\nSocial History:\\n___\\nFamily History:\\nNon-contributory\\n \\nMedications on Admission:\\nThe Preadmission Medication list is accurate and complete.\\n1. Clopidogrel 75 mg PO DAILY \\n2. Acetaminophen 1000 mg PO Q6H \\n3. Atorvastatin 40 mg PO QPM \\n4. Flovent HFA (fluticasone) 44 mcg/actuation inhalation BID \\n5. FoLIC Acid 1 mg PO DAILY \\n6. Furosemide 40 mg PO DAILY \\n7. Lisinopril 2.5 mg PO DAILY \\n8. Metoprolol Succinate XL 25 mg PO DAILY \\n9. Multivitamins 1 TAB PO DAILY \\n10. Spironolactone 12.5 mg PO DAILY \\n11. Vitamin D ___ UNIT PO DAILY \\n12. Pantoprazole 40 mg PO Q24H \\n13. Warfarin 2.5 mg PO 6X/WEEK (___) \\n\\n Examine the ECG. Identify any indications of ST elevation in the patient.\"},\n",
       "   {'from': 'gpt',\n",
       "    'value': 'The ECG findings do not indicate ST elevation.'}]},\n",
       " {'id': 47548370,\n",
       "  'image': '47548370.jpeg',\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': 'Your prior assessment was: The ECG findings do not indicate ST elevation. Please examine the ECG to identify any evidence of ST depression or T-wave inversion in the patient.'},\n",
       "   {'from': 'gpt',\n",
       "    'value': 'The ECG displays no evidence of ST depression or T-wave inversion.'}]},\n",
       " {'id': 47548370,\n",
       "  'image': '47548370.jpeg',\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': 'Your prior assessment was: The ECG displays no evidence of ST depression or T-wave inversion.. Would you advise performing a troponin test?'},\n",
       "   {'from': 'gpt', 'value': 'No, we should not order a troponin test.'}]},\n",
       " {'id': 47548370,\n",
       "  'image': '47548370.jpeg',\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': 'Your prior assessment was: No, we should not order a troponin test.. Could the patient be having a myocardial infarction?'},\n",
       "   {'from': 'gpt',\n",
       "    'value': 'The patient is not undergoing a myocardial infarction.'}]},\n",
       " {'id': 46777990,\n",
       "  'image': '46777990.jpeg',\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': \"<image>\\nAllergies: \\nQuinine / shellfish derived / caffeine / Reglan / Vantin / \\nMidodrine / Hyzaar / Zocor\\n \\nChief Complaint:\\nICD lead extraction\\n \\nMajor Surgical or Invasive Procedure:\\nRight ventricular lead and ICD explant\\nBiventricular ICD implant\\n\\n(LV lead replacement)\\n \\nHistory of Present Illness:\\n___ yo F hx CAD (70% LAD on med management), Afib (refractory \\namiodarone s/p 3 DCCV), non-ischemic cardiomyopathy with EF \\n___ s/p SJM Bi-V ICD with Riata RV lead in ___ with \\nLV lead turned off in ___ due to persistent diaphragmatic \\nirritation p/f extraction of RV Riata lead and LV lead now s/p \\nexplantation of RV Riata with reimplantation of new RV lead. \\n\\nAt baseline patient is able to ambulate with walker across 2 \\nrooms and back without becoming short of breath. Maintained on \\nfurosemide 40mg. Has intermittent ankle edema for which she will \\ntake 80mg furosemide. Denies orthopnea, PND. Started on digoxin \\nabout 6 weeks ago which patient says has greatly improved her \\nDOE. SJM Bi-V ICD was implanted in ___. Afterwards patient had \\npersistent hiccups severe enough to limit fluent speech for ___ \\nyears. The LV lead was turned off in ___ due to no clinical \\nbenefit and persistent diaphragmatic stimulation. Hiccups \\nresolved subsequently. Her battery has been at ERI since \\n___.  \\n\\nShe also has a history significant for atrial fibrillation first \\ndiagnosed in the ___, which has been persistent since ___ and \\nis now permanent.  She is on Coumadin which has been managed by \\nDr ___ this procedure.  The patient has failed \\namiodarone and is status post ___ cardioversions.  She has CAD \\nwith 70% LAD stenosis shown on cath in ___ at ___ \\nwhich has been treated medically. Not currently on a Statin due \\nto GI upset. Pt also not on ASA.\\n\\nShe also has moderate to severe MR and a LBBB, moderate to \\nsevere pulmonary HTN, renal insufficiency and a history of GI \\nbleed in ___.  Patient was referred for right and left \\nventricular lead explant and biventricular implantable \\ncardioverter defibrillator implantation by Dr ___ in the \\nOR, which was successfully done on ___. Subsequently was \\nconfused in PACU and nauseated on transfer to floor, but this \\nhas resolved.\\n\\nOn review of systems, s/he denies any prior history of stroke, \\nTIA, deep venous thrombosis, pulmonary embolism, joint pains, \\ncough, hemoptysis, black stools or red stools. S/he denies \\nrecent fevers, chills or rigors. S/he denies exertional buttock \\nor calf pain. All of the other review of systems were negative.  \\n\\nCardiac review of systems is notable for absence of chest pain, \\nparoxysmal nocturnal dyspnea, orthopnea, palpitations, syncope \\nor presyncope. \\n \\nPast Medical History:\\nSocial History:\\n___\\nFamily History:\\nNo family history of early MI, arrhythmia, cardiomyopathies, or \\nsudden cardiac death; otherwise non-contributory.  \\n \\nMedications on Admission:\\nThe Preadmission Medication list is accurate and complete.\\n1. Digoxin 0.125 mg PO DAILY \\n2. Metoprolol Succinate XL 50 mg PO DAILY \\n3. Warfarin 2 mg PO DAILY16 \\n4. Furosemide 40 mg PO DAILY \\n5. Spironolactone 25 mg PO DAILY \\n6. Pantoprazole 40 mg PO Q24H \\n7. Levothyroxine Sodium 75 mcg PO DAILY \\n\\n Analyze this patient's ECG. Assess whether ST elevation is present.\"},\n",
       "   {'from': 'gpt', 'value': 'No, the ECG does not show ST elevation.'}]}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/test_conversations_single_qa.json', 'w') as f:\n",
    "    json.dump(qa_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing conversations: 100%|██████████| 24000/24000 [00:05<00:00, 4514.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total QA pairs extracted: 90451\n"
     ]
    }
   ],
   "source": [
    "qa_list = transform_to_qa(train_conversations)\n",
    "print(f\"Total QA pairs extracted: {len(qa_list)}\")\n",
    "\n",
    "with open('../../data/train_conversations_single_qa.json', 'w') as f:\n",
    "    json.dump(qa_list, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
